{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##进行xgboost的训练\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gc\n",
    "import csv\n",
    "import time \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.externals import joblib"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_train = './out_put/encode_data_train.csv'\n",
    "file_vali = './out_put/encode_data_vali.csv'\n",
    "file_test = './out_put/encode_data_test.csv'\n",
    "\n",
    "df_train = pd.read_csv(file_train, index_col = 0)\n",
    "df_vali = pd.read_csv(file_vali, index_col = 0)\n",
    "df_test = pd.read_csv(file_test, index_col = 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##数据准备\n",
    "y_train = df_train['click']\n",
    "x_train = df_train.iloc[:,1:]  #从第二个开始往又所有\n",
    "print('=' * 10)\n",
    "print(x_train)\n",
    "print('=' * 10)\n",
    "\n",
    "y_vali = df_vali['click']\n",
    "x_vali = df_vali.iloc[:,1:]\n",
    "\n",
    "y_test = df_test['click']\n",
    "x_test = df_test.iloc[:,1:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##进行xgboost拟合\n",
    "begin_time = time.time()\n",
    "print(f'Begin Time : {time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(begin_time))}')\n",
    "\n",
    "##受限于机器的资源，这里就不做gridsearch调参了，直接凑合着来(按最小资源消耗来设置参数)\n",
    "model = XGBClassifier(learning_rate=0.1  # 学习率，过大收敛不了，小了收敛慢\n",
    "                     ,n_estimators=10\n",
    "                     ,max_depth=3     # 构建树的深度，越大越容易过拟合，可以用CV函数来进行调优\n",
    "                     ,scale_pos_weight=1  # 正样本的权重，在二分类任务中，当正负样本比例失衡时，设置正样本的权重，模型效果更好。例如，当正负样本比例为1:10时，scale_pos_weight=10。\n",
    "                     ,min_child_weight=1  # 叶子里面h的和，h就是二阶导不清楚的看看xgboost原理，该参数越小越容易过拟合\n",
    "                     ,gamma=0  # 树的叶子节点上作进一步分区所需的最小损失减少,越大越保守，一般0.1、0.2这样子\n",
    "                     ,subsample=1  # 随机采样训练样本 训练实例的子采样比，典型值的范围在0.5-0.9之间。\n",
    "                     ,colsample_bylevel=1  # 生成树时进行的列采样 同subsample，一般在0.5-0.9\n",
    "                     ,objective='binary:logistic'   #二分类的问题,概率\n",
    "                     ,n_jobs=4  #  并行线程数\n",
    "                     ,seed=100\n",
    "                     ,nthread=4  # 使用4个cpu进行计算\n",
    "                      )\n",
    "\n",
    "eval_set = [(x_vali, y_vali)]\n",
    "model.fit(x_train, y_train, eval_metric=\"auc\" , eval_set=eval_set, early_stopping_rounds=10)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f'End Time : {time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(end_time))}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##保存xgb的model\n",
    "joblib.dump(model, './model/xgb_model.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#我们来拿到xgb的叶子节点的特征\n",
    "##进行xgboost拟合\n",
    "begin_time = time.time()\n",
    "print(f'Begin Time : {time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(begin_time))}')\n",
    "\n",
    "##apply函数返回的是叶子索引\n",
    "x_train_leaves = model.apply(x_train).astype(np.int32)\n",
    "x_test_leaves = model.apply(x_test).astype(np.int32)\n",
    "\n",
    "#使用numpy的concatenate来拼接数组，并生成全局的onehot，单一使用train的可能会漏掉编码，test验证的时候出问题\n",
    "x_leaves = np.concatenate((x_train_leaves,x_test_leaves), axis=0)  #axis=0二维纵向拼接,union\n",
    "print(x_leaves)\n",
    "\n",
    "print(f'Transform xgb leaves shape: {x_leaves.shape}')  # (859999, 10)\n",
    "\n",
    "xgb_onehotcoder = OneHotEncoder()\n",
    "xgb_onehotcoder.fit(x_leaves)\n",
    "\n",
    "x_train_lr = xgb_onehotcoder.transform(x_train_leaves).toarray()  # 转成one-hot编码\n",
    "x_test_lr = xgb_onehotcoder.transform(x_test_leaves).toarray()    # 转成one-hot编码\n",
    "print(f'Transform xgb x_train_lr shape: {x_train_lr.shape}')  # (559999, 80)\n",
    "print(f'Transform xgb x_test_lr shape: {x_test_lr.shape}') # (300000, 80)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f'End Time : {time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(end_time))}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ##机器资源较小，进行部分变量内存回收\n",
    "# del df_train, df_vali, df_test, x_vali, x_train_leaves, x_test_leaves, x_leaves, xgb_onehotcoder\n",
    "# gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# np_train_lr = np.hstack((np.array(np.mat(y_train).transpose()),x_train_lr))\n",
    "# np.savetxt(\"./out_put/encode_data_train_lr.csv\", np_train_lr, delimiter=',')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# del np_train_lr\n",
    "# gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# np_test_lr = np.hstack((np.array(np.mat(y_test).transpose()),x_test_lr))\n",
    "# np.savetxt(\"./out_put/encode_data_test_lr.csv\", np_test_lr, delimiter=',')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# del np_test_lr\n",
    "# gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##进行one特征与原始特征的拼接\n",
    "x_train_lr2 = np.hstack((x_train_lr, x_train.values))  # :在水平方向上平铺,横向\n",
    "print(f'Transform xgb x_train_lr2 shape: {x_train_lr2.shape}')  # (559999, 101)\n",
    "\n",
    "# np_train_lr2 = np.hstack((np.array(np.mat(y_train).transpose()),x_train_lr2))\n",
    "# np.savetxt(\"./out_put/encode_data_train_lr2.csv\", np_train_lr2, delimiter=',')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# del x_train,x_train_lr,x_train_lr2,np_train_lr2\n",
    "# gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_test_lr2 = np.hstack((x_test_lr, x_test.values))\n",
    "print(f'Transform xgb x_test_lr2 shape: {x_test_lr2.shape}')  # (300000, 101)\n",
    "\n",
    "# np_test_lr2 = np.hstack((np.array(np.mat(y_test).transpose()),x_test_lr2))\n",
    "# np.savetxt(\"./out_put/encode_data_test_lr2.csv\", np_test_lr2, delimiter=',')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##回收部分资源，资源不够了\n",
    "del df_train,df_vali,df_test,x_vali,x_train_leaves,x_test_leaves,x_leaves,xgb_onehotcoder\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "###灌入到LR中\n",
    "begin_time = time.time()\n",
    "print(f'Begin Time : {time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(begin_time))}')\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(x_train_lr, y_train)\n",
    "\n",
    "lr_model2 = LogisticRegression()\n",
    "lr_model2.fit(x_train_lr2, y_train)\n",
    "\n",
    "joblib.dump(lr_model, './model/lr_model.pkl')\n",
    "joblib.dump(lr_model2, './model/lr_model2.pkl')\n",
    "\n",
    "end_time = time.time()\n",
    "print(f'End Time : {time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(end_time))}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##效果输出函数\n",
    "def func_print_score(x_data,y_data,data_type,model_x):\n",
    "    y_pred = model_x.predict(x_data)\n",
    "    \n",
    "    print(f'==============({data_type})===================')\n",
    "    confusion = metrics.confusion_matrix(y_data, y_pred)\n",
    "    print(confusion)\n",
    "    \n",
    "    print('------------------------')\n",
    "    auc = metrics.roc_auc_score(y_data,y_pred)\n",
    "    print(f'AUC: {auc}')\n",
    "    \n",
    "    print('------------------------')\n",
    "    accuracy = metrics.accuracy_score(y_data,y_pred)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    \n",
    "    print('------------------------')\n",
    "    aupr = metrics.average_precision_score(y_data, y_pred)\n",
    "    print(f'AUPR: {aupr}')\n",
    "    \n",
    "    print('------------------------')\n",
    "    report = metrics.classification_report(y_data, y_pred)\n",
    "    print(report) \n",
    "    \n",
    "    print('=============================================')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "func_print_score(x_test,y_test,'testdata-xgb', model)\n",
    "func_print_score(x_test_lr,y_test,'testdata-xgb-lr', lr_model)  # one-hot编码后的\n",
    "func_print_score(x_test_lr2,y_test,'testdata-xgb-lr2', lr_model2) # 合并后的"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del x_train,y_train,x_train_lr,x_train_lr2\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##测试数据的PR曲线\n",
    "# model.predict_proba 返回预测属于某标签的概率 https://www.cnblogs.com/mrtop/p/10309083.html\n",
    "probas_xgb = model.predict_proba(x_test)\n",
    "probas_lr = lr_model.predict_proba(x_test_lr)\n",
    "probas_lr2 = lr_model2.predict_proba(x_test_lr2)\n",
    "\n",
    "print(model.predict(x_test))\n",
    "\n",
    "print(probas_xgb)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##precision_recall_curve 函数\n",
    "precision_xgb,recall_xgb, thresholds_xgb = metrics.precision_recall_curve(y_test, probas_xgb[:,1])\n",
    "precision_lr,recall_lr, thresholds_lr = metrics.precision_recall_curve(y_test, probas_lr[:,1])\n",
    "precision_lr2,recall_lr2, thresholds_lr2 = metrics.precision_recall_curve(y_test, probas_lr2[:,1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.plot(recall_xgb, precision_xgb, label = 'xgb', alpha = 0.8, color = 'red')\n",
    "plt.plot(recall_lr, precision_lr, label = 'xgg-lr', alpha = 0.8, color = 'blue')\n",
    "plt.plot(recall_lr2, precision_lr2, label = 'xgb-lr2', alpha = 0.8, color = 'green')\n",
    "\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "\n",
    "#图例打印\n",
    "plt.legend(bbox_to_anchor=(1.05, 0), loc = 3, borderaxespad = 1)\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "\n",
    "plt.xlabel('Recall Rate')\n",
    "plt.ylabel('Precision Rate')\n",
    "plt.title('PR Curve')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}